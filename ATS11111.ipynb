{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LATS_demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehulsingh10/Age-Transformation-Synthesis/blob/master/ATS11111.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jny9CGNw1Rjn"
      },
      "source": [
        "# Age Transformation Synthesis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhbnEdCV2kc-"
      },
      "source": [
        "Downloading the Github repository and installing all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2uubo7PsvxQ"
      },
      "source": [
        "!git clone https://github.com/mehulsingh10/Age-Transformation-Synthesis\n",
        "%cd Age-Transformation-Synthesis/\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKKNh_xl3AI2"
      },
      "source": [
        "Downloading the pretrained models for males and females."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ezAOkaHw4Q_"
      },
      "source": [
        "!python download_models.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKl8INdX3IHv"
      },
      "source": [
        "Here, we import libraries and set options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQKoh2xrw697"
      },
      "source": [
        "import os\n",
        "from collections import OrderedDict\n",
        "from options.test_options import TestOptions\n",
        "from data.data_loader import CreateDataLoader\n",
        "from models.models import create_model\n",
        "import util.util as util\n",
        "from util.visualizer import Visualizer\n",
        "\n",
        "opt = TestOptions().parse(save=False)\n",
        "opt.display_id = 0 # do not launch visdom\n",
        "opt.nThreads = 1   # test code only supports nThreads = 1\n",
        "opt.batchSize = 1  # test code only supports batchSize = 1\n",
        "opt.serial_batches = True  # no shuffle\n",
        "opt.no_flip = True  # no flip\n",
        "opt.in_the_wild = True # This triggers preprocessing of in the wild images in the dataloader\n",
        "opt.traverse = True # This tells the model to traverse the latent space between anchor classes\n",
        "opt.interp_step = 0.05 # this controls the number of images to interpolate between anchor classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AFlzSi41Kzg"
      },
      "source": [
        "Calling the data loader and the visualizer class that generates the video from the network outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxBYeTB18zkZ"
      },
      "source": [
        "data_loader = CreateDataLoader(opt)\n",
        "dataset = data_loader.load_data()\n",
        "visualizer = Visualizer(opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AbUVdK74G5p"
      },
      "source": [
        "Defining our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_0RChfq0YPr"
      },
      "source": [
        "opt.name = 'males_model' # change to 'females_model' if you're trying the code on a female image\n",
        "model = create_model(opt)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APhLIBEg4gnk"
      },
      "source": [
        "Upload the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSUbmd697Api"
      },
      "source": [
        "# upload your image (the code supports only a single image at a time)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  img_path = filename\n",
        "  print('User uploaded file \"{name}\"'.format(name=filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgxXQ4tu45V5"
      },
      "source": [
        "Finally, we preprocess the image, run the network, and save the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ3Az0VY3Fwt"
      },
      "source": [
        "data = dataset.dataset.get_item_from_path(img_path)\n",
        "visuals = model.inference(data)\n",
        "\n",
        "os.makedirs('results', exist_ok=True)\n",
        "out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.mp4')\n",
        "visualizer.make_video(visuals, out_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRCyM2i65ZdB"
      },
      "source": [
        "Final Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwjp6STO3hCz"
      },
      "source": [
        "use_webm = False\n",
        "\n",
        "!pip3 install webm\n",
        "webm_out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.webm')\n",
        "!webm -i $out_path $webm_out_path\n",
        "use_webm = True\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "video_path = webm_out_path if use_webm else out_path\n",
        "video_type = \"video/webm\" if use_webm else \"video/mp4\"\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width={0} controls>\n",
        "      <source src=\"{1}\" type=\"{2}\">\n",
        "</video>\n",
        "\"\"\".format(opt.fineSize, data_url, video_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W87da7s9FM1"
      },
      "source": [
        "files.download(out_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}